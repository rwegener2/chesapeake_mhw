{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e910d609-ba07-4b95-ba5d-a3fef83af487",
   "metadata": {},
   "source": [
    "# Download Chesapeake Bay Program Water Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ceea48-e72c-40bd-949e-2a33e8cc4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fd0a27-bda9-4ef5-bb8a-391ffe42c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ROOT = '/Users/rwegener/repos/chesapeake_mhw/'\n",
    "\n",
    "start_date = datetime(2003, 1, 1)\n",
    "end_date = datetime(2022, 12, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84a398-5484-4084-b59e-14c984b04e2a",
   "metadata": {},
   "source": [
    "Temp, Sal, DO download:\n",
    "\n",
    "https://datahub.chesapeakebay.net/api.Tab/WaterQuality/WaterQuality/12-8-2018/12-8-2023/0/2,4,6/12,13,15,35,36,2,3,7,33,34,23,24/HUC8/2,4,6,7,8,9,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60/31,123,83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8afb8417-7123-4c5f-a86e-0af43966f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_request_temponly(start, end):\n",
    "    '''\n",
    "    Creating URL string for requesting water quality data from the Chesapeake Bay \n",
    "    Program.\n",
    "    \n",
    "    Start and end date formatted as `month-day-year`, or '%m-%d-%Y' \n",
    "    using https://strftime.org/\n",
    "    '''\n",
    "    return (\n",
    "        'https://datahub.chesapeakebay.net/api.CSV/WaterQuality/WaterQuality/'\n",
    "        f'{start}/{end}/0/2,4,6/12,13,15,35,36,2,3,7,33,34,23,24/HUC8/'\n",
    "        '2,4,6,7,8,9,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31'\n",
    "        ',32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60/123'\n",
    "    )\n",
    "\n",
    "def format_request_tempDOsal(start, end):\n",
    "    '''\n",
    "    Creating URL string for requesting water quality data from the Chesapeake Bay \n",
    "    Program.\n",
    "    \n",
    "    Start and end date formatted as `month-day-year`, or '%m-%d-%Y' \n",
    "    using https://strftime.org/\n",
    "    '''\n",
    "    return (\n",
    "        'https://datahub.chesapeakebay.net/api.CSV/WaterQuality/WaterQuality/'\n",
    "        f'{start}/{end}/0/2,4,6/12,13,15,35,36,2,3,7,33,34,23,24/HUC8/'\n",
    "        '2,4,6,7,8,9,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31'\n",
    "        ',32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60/31,123,83'\n",
    "    )\n",
    "\n",
    "format_request = format_request_tempDOsal\n",
    "# The API seems to get overwhelmed when requesting the full 20 years of data at once.\n",
    "# The request is instead split into one request per decade and the data frames are merged.\n",
    "\n",
    "# Create temporary filepaths\n",
    "scratch_dir = tempfile.TemporaryDirectory()\n",
    "decade1_path = os.path.join(scratch_dir.name, 'decade1.csv')\n",
    "decade2_path = os.path.join(scratch_dir.name, 'decade2.csv')\n",
    "decade3_path = os.path.join(scratch_dir.name, 'decade3.csv')\n",
    "\n",
    "# Request #1 -- ~2002-2008\n",
    "response = requests.get(format_request(start_date.strftime('%m-%d-%Y'), '12-31-2008'))\n",
    "response.raise_for_status() # ensure we notice bad responses\n",
    "with open(decade1_path, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "# Request #2 -- ~2009-2015\n",
    "response = requests.get(format_request('01-01-2009', '12-31-2015'))\n",
    "response.raise_for_status() # ensure we notice bad responses\n",
    "with open(decade2_path, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "# Request #3 -- ~2016-2022\n",
    "response = requests.get(format_request('01-01-2016', end_date.strftime('%m-%d-%Y')))\n",
    "response.raise_for_status() # ensure we notice bad responses\n",
    "with open(decade3_path, \"w\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2332486-bd0b-47f1-a86e-25bd3112191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/985fq4dx1356qtcv5dd4zgyr0000gn/T/ipykernel_38445/374804961.py:2: DtypeWarning: Columns (0,22,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  decade1_df = pd.read_csv(decade1_path)\n",
      "/var/folders/p8/985fq4dx1356qtcv5dd4zgyr0000gn/T/ipykernel_38445/374804961.py:3: DtypeWarning: Columns (0,18,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  decade2_df = pd.read_csv(decade2_path)\n",
      "/var/folders/p8/985fq4dx1356qtcv5dd4zgyr0000gn/T/ipykernel_38445/374804961.py:4: DtypeWarning: Columns (0,18,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  decade3_df = pd.read_csv(decade2_path)\n"
     ]
    }
   ],
   "source": [
    "# Open the csvs using pandas\n",
    "decade1_df = pd.read_csv(decade1_path)\n",
    "decade2_df = pd.read_csv(decade2_path)\n",
    "decade3_df = pd.read_csv(decade2_path)\n",
    "\n",
    "# Combine the datasets\n",
    "full_df = pd.concat([decade1_df, decade2_df, decade3_df])\n",
    "\n",
    "# Sort by date and reset the index\n",
    "full_df.SampleDate = pd.to_datetime(full_df.SampleDate)\n",
    "full_df = full_df.sort_values('SampleDate').reset_index(drop=True)\n",
    "\n",
    "# Remove rows with null temperature values\n",
    "full_df = full_df[~full_df.MeasureValue.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43befcfe-bd3c-44d9-b2bc-2594d2e323a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the raw data folder\n",
    "filename = (\n",
    "    'WaterQuality_ChesapeakeBayProgram_{}_{}_TempDOSal.csv'\n",
    "    ).format(start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d'))\n",
    "output_path = os.path.join(REPO_ROOT, 'data/raw', filename)\n",
    "\n",
    "full_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7156584-6cdb-4101-ab10-25fac6f0ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the temporary directory\n",
    "scratch_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7ae94-8f17-4a94-a652-f8b2130fb2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chesapeake_mhw_2021dask]",
   "language": "python",
   "name": "conda-env-chesapeake_mhw_2021dask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
